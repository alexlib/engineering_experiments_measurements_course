{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short summary of the ``Measurement good practice guide '' by NPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a measurement\n",
    "\n",
    "A measurement is a single value that is measured at a single point in time. It is a process of giving a value (number) to a certain property (length, mass, height, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is not a measurement\n",
    "\n",
    "1. comparing two things is not a measurement (no value)\n",
    "2. counting is not a measurement (no uncertainty)\n",
    "3. test yes/no is not a measurement (not a property value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty of measurement\n",
    "\n",
    "The uncertainty is the value we give to the quality of measurement - to the quality of how good the measured value is or how certain we are about that value\n",
    "\n",
    "_uncertainty of measurement is the doubt that exists about the result of any measurement_\n",
    "\n",
    "### Expressing uncertainty of measurement \n",
    "\n",
    "We answer two questions: how big is the margin around the best estimate of measurement value and how certain or how bad is the doubt - therefore we provide two numbers: the width of the margin or _interval_ and the _confidence level_ \n",
    "\n",
    "Example:\n",
    "\n",
    "The length of the rod is measured as 20 cm plus or minus 1 cm at the 95\\% confidence level: \n",
    "\n",
    "$ 20 \\pm 1 $ cm, at a level of confidence $ 95\\% $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error is not uncertainty \n",
    "\n",
    "This is the most common remark on all the exams in our course ;) \n",
    "\n",
    "We CANNOT confuse **error** with **uncertainty** : \n",
    "\n",
    "**error** is the difference between the measured value (a result of act of measurement) and the ``true`` value. \n",
    "\n",
    "**uncertainty** is a quantification (giving a value to the doubt) of the doubt about the measurement result. \n",
    "\n",
    "\n",
    "Let's see an example: we measure weight - we see on the weight the value 82 kg. We know that the value is 82 kg but the real, true weight is somewhere near, maybe 81.5 or 82.3. E.g. assume the real, true value is 82.3 then it means that our **measurement error** is 0.3 kg. (82.3 - 82 = 0.3)\n",
    "\n",
    "However, when we think about uncertainty we shall also wonder whether we did it right, do we stand correct on the weight? is the weight calibrated? maybe we shall do it several times, etc. i.e. we feel that 82 kg that the weight shows only some value (one measurement) but it does not say anything about the next value we will get if we try to measure again, using this weight scale or another, maybe using different method, etc. We want to estimate the weight and we could only know it with **some uncertainty and for some confidence level**. So we could say that we estimate our weight to be $ 82 \\pm 1.5 $ kg at 95\\% confidence level. Where the value 1.5 is coming from? That's our course is about. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure several times before you cut\n",
    "\n",
    "\n",
    "From Britannica: \"MEASURE seven times, cut once \n",
    "\n",
    "Russian proverb, originally referring to carpentry and needlework, meaning that care taken in preparation will prevent errors;\" \n",
    "\n",
    "\n",
    "English version: '' measure thrice and cut onceâ€‹ '' \n",
    "\n",
    "In this course it means that we can **improve the quality of measurement** by reducing uncertainty or in other words by careful planning and analysis. We also learn that if we repeat the measurement, the risk of making a large error is reduced and we get closer to the true value (never completely close, only closer). We need here some statistics knowledge to use to get a better estimate. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring something only once can easily be a random value - the mistake goes unnounced and we find ourselves believing in a non-existing number. \n",
    "\n",
    "Recommendation - at least 3 times\n",
    "\n",
    "If you do two measurements that these do not agree, (they never agree, there is no such a thing in nature, only if we round up our measureements), we do not know which one is more correct and which one is less. So repeating is a way to reduce the *operator error* - only one aspect of error due to the human operator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "We learned in statistics when we have multiple random values that are associated with measurements, we want to know how to get the best estimate out of these numbers and how to quantify the possible width of the margin around that basic estimate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facts: \n",
    "    * repeated measurements always show different values  \n",
    "    * this is natural and normal - you do not do anything wrong.   \n",
    "    * best way to estimate the value if we have repeated measurements is to take the average   \n",
    "    * how many measurements do we need to get a good estimate? The short answer as long as we agree about it.   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best estimates are average and standard deviation:\n",
    "\n",
    "$$ \\bar{x} = \\frac{1}{N} \\sum\\limits_{i=1}^{N} x_i $$\n",
    "\n",
    "$$ s_x = \\sqrt{ \\frac{\\sum\\limits_{i=1}^{N} (x_i - \\bar{x})^2 }{N-1} } $$\n",
    "\n",
    "where $x_i$ is $i$-th measurement, $i=1...N$ of any quantity $x$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do errors and uncertainties come from?\n",
    "\n",
    "- the measuring instrument\n",
    "- the item being measured - items are not perfect, not stable, not representative\n",
    "- the measurement process\n",
    "- \"imported\" uncertainties: calibration, known values\n",
    "- operator skills\n",
    "- sampling process\n",
    "- the environment: temperature, air pressure, humidity, radiation, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different kinds of uncertainty\n",
    "\n",
    "1. random - repeating measurements give different values. more measurement repetitions, the better the average represents the true value\n",
    "2. systematic (bias) -  same influence on all the repeating measurements. more measurements cannot help, only use of different instrument, different operator, different environment, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spread of random variables - distribution shape\n",
    "\n",
    "1. Normal distribution\n",
    "2. uniform or rectangular distribution\n",
    "3. triangular\n",
    "4. bi-modal (M-shaped, or two-peaks)\n",
    "5. t-distribution\n",
    "\n",
    "We will explain in separate notebooks each one of those and why and how to use those"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is not measurement uncertainty\n",
    "\n",
    "1. mistakes - not an error in measurement, simply using the wrong instrument, recording a wrong scale, etc. should be carefully checked and avoided\n",
    "2. tolerances - not uncertainties, but some accepted limits for a product or process\n",
    "3. specifications - only prescribes what to expect from the product\n",
    "4. accuracy - a word which is qualitative description. we use uncertainty - a quantitative value that prescribes exactly how accurate or not accurate the measurement result\n",
    "5. **errors are not the same as uncertainties**, although sometimes we use by mistake error analysis instead of uncertainty analysis. we will talk about it in detail. simple answer - error is a single measurement distance from a true value, but it is just a given value at a given time, by a given instrument and operator. every new measurement will give another error. All these errors, plus other errors, scaled by their proper distributions (different events - different statistics or distributions) - will become that \"measure of doubt\" that we call **uncertainty**\n",
    "6. statistical analysis helps to estimate uncertainty, but it is not the same, it is just one part of the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two types of uncertainty\n",
    "\n",
    "**Type A** - uncertainty estimates using statistics of repeated measurements (average, standard deviation, distribution) \n",
    "\n",
    "**Type B** - uncertainty estimates from any other information, such as past experience, calibration certificates, manufacturer specifications, calculations, published information, common sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
